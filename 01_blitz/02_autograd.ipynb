{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing pre trained model\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random image (3 chanels, 64x64 pixels) (why that 1???)\n",
    "data = torch.rand(size = (1, 3, 64, 64))\n",
    "\n",
    "# random labels\n",
    "labels = torch.rand(1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.6885e-01, -3.7314e-01, -3.9696e-01, -1.3377e+00, -3.9721e-01,\n",
       "         -2.5575e-02, -6.9607e-01,  6.7276e-01,  4.0998e-01, -7.0392e-01,\n",
       "         -7.7152e-01, -7.1203e-01, -2.9793e-01, -5.3480e-01, -1.2263e+00,\n",
       "         -2.1339e-01, -5.0849e-01, -4.1842e-02, -2.0528e-01, -4.0935e-01,\n",
       "         -1.1893e+00, -4.5670e-01, -1.3280e+00,  3.4494e-01, -1.1563e+00,\n",
       "         -1.0931e+00, -8.4165e-01, -1.1085e+00, -8.9042e-01, -1.3943e-01,\n",
       "         -7.2850e-01, -7.9842e-01, -5.2842e-01, -5.8157e-01, -4.1097e-01,\n",
       "         -2.3199e-01,  4.4488e-01, -8.2976e-01, -3.8191e-01,  2.1901e-01,\n",
       "         -6.1787e-01, -8.7953e-01, -8.4999e-01, -4.2746e-01, -2.5749e-01,\n",
       "         -4.1676e-01, -7.0803e-01, -3.2501e-01, -1.0683e+00, -1.0845e+00,\n",
       "         -7.0636e-01,  9.9255e-01, -3.7412e-01, -5.7979e-01, -2.2219e-01,\n",
       "         -1.2825e+00, -4.4568e-01, -1.5992e+00, -4.4202e-01, -4.7013e-01,\n",
       "          7.4405e-01,  5.3861e-02, -7.5765e-02, -3.3908e-02, -6.8063e-01,\n",
       "         -3.6045e-01, -2.9525e-01, -5.0254e-01, -8.5655e-01, -1.1679e+00,\n",
       "         -1.5753e+00,  9.2744e-02, -1.7308e+00, -5.9789e-01, -1.3181e+00,\n",
       "         -1.5896e+00,  1.9111e-01, -5.0710e-01,  2.3565e-01,  7.0370e-02,\n",
       "         -5.7650e-01, -1.2622e+00,  1.7569e-01, -8.2807e-01, -5.3386e-01,\n",
       "          2.0082e-01,  2.2068e-01,  3.3663e-01,  5.6755e-02, -3.3464e-01,\n",
       "         -1.1982e+00, -8.7886e-01, -1.9621e+00, -3.8474e-02,  2.9537e-01,\n",
       "         -1.9958e+00, -4.4262e-01, -4.2241e-01, -1.1683e+00, -3.0709e-02,\n",
       "         -1.3922e+00, -1.0863e+00, -1.0482e+00, -2.3258e-01,  1.1975e-01,\n",
       "         -7.2575e-01, -2.5616e-01, -1.4118e+00, -1.0560e+00, -1.4203e+00,\n",
       "         -1.2756e+00, -7.1207e-01,  9.2455e-01,  4.2421e-01,  5.0786e-01,\n",
       "         -9.3138e-01, -6.2559e-01, -1.0331e-01,  4.1110e-01, -1.7290e-01,\n",
       "         -6.8853e-01, -5.1636e-02,  1.4938e-01, -1.0578e-01,  1.0269e+00,\n",
       "          1.4297e-01,  4.5740e-01, -1.0791e+00, -9.8727e-01, -8.9490e-01,\n",
       "         -1.4139e+00, -1.3889e+00, -9.3683e-01, -1.4621e+00, -4.3808e-01,\n",
       "         -1.3923e+00, -8.8913e-01, -9.1446e-01, -1.1130e+00, -1.2718e+00,\n",
       "         -1.5102e+00, -1.7874e+00, -2.1117e+00, -1.1238e+00, -4.6798e-01,\n",
       "         -4.4702e-01, -6.4028e-01, -1.7440e+00, -1.2171e+00, -1.1827e+00,\n",
       "          3.3061e-01,  1.7014e+00, -1.0565e+00, -4.2618e-01,  6.3696e-02,\n",
       "          1.5190e-01, -3.2647e-01, -2.0966e-01,  1.5723e-01,  3.9831e-02,\n",
       "          4.7169e-01,  9.6906e-01,  3.1335e-01,  7.2639e-01,  9.5524e-02,\n",
       "         -2.7390e-01, -1.4171e-01, -2.8605e-01,  3.8895e-01, -1.5699e-02,\n",
       "          2.1836e-01,  9.0442e-01,  7.1045e-01,  5.4074e-01,  2.2752e-01,\n",
       "         -8.0105e-01,  1.7688e-01,  1.5058e-01,  5.9693e-01,  6.2847e-01,\n",
       "          6.1225e-01, -2.9946e-01,  7.4955e-01, -1.4032e-02,  7.9011e-01,\n",
       "          9.7251e-01,  7.5629e-01,  1.4339e-01,  3.4503e-01,  7.9297e-01,\n",
       "         -3.0887e-01,  5.3265e-01,  7.4139e-01,  4.6645e-01, -5.3713e-01,\n",
       "          9.4952e-01,  3.5933e-01,  2.2306e-01,  3.2665e-01,  1.0578e+00,\n",
       "          1.5949e-02,  6.1318e-02,  7.1496e-01,  7.6929e-01,  2.2653e-01,\n",
       "          3.0885e-01, -2.8457e-01,  7.1654e-01,  1.2837e+00,  4.9178e-01,\n",
       "         -3.4562e-01,  1.3748e-01,  4.6571e-01, -1.2757e-01,  3.0888e-02,\n",
       "          3.2766e-01, -1.0863e-01,  2.8914e-01, -2.2436e-01,  6.6160e-01,\n",
       "         -4.6123e-03, -5.3644e-01,  2.5944e-02,  7.5005e-01,  3.9745e-01,\n",
       "          7.4253e-01,  2.2082e-01,  7.4960e-01, -4.3790e-01, -4.8784e-02,\n",
       "          5.5179e-02,  7.5449e-01,  4.6340e-01, -1.7457e-01,  7.7444e-01,\n",
       "          9.1763e-01,  3.0457e-01,  4.6382e-01,  7.9607e-01,  9.1391e-02,\n",
       "          6.4692e-01,  4.4957e-04,  3.9319e-01,  4.7413e-01, -4.6749e-01,\n",
       "          8.4804e-01,  5.8645e-01,  2.3512e-01,  6.3028e-01,  2.6703e-01,\n",
       "          5.1178e-01,  4.7713e-01, -7.2494e-01,  7.0202e-01,  9.6196e-01,\n",
       "         -5.5051e-01,  5.6503e-01,  4.2069e-01, -1.7422e-01,  1.7791e-01,\n",
       "         -3.7998e-01, -7.2703e-01, -9.3462e-03,  7.3316e-01,  1.0186e+00,\n",
       "          5.4683e-01, -8.2864e-03,  2.3641e-01, -1.2489e-02, -2.3639e-01,\n",
       "         -6.8717e-01, -1.0132e+00, -4.7107e-01,  8.9494e-01, -8.7357e-01,\n",
       "         -6.3814e-01, -8.4071e-01, -6.5594e-01, -1.0775e+00, -4.1905e-01,\n",
       "         -2.0871e-01,  8.3960e-01,  7.5601e-01,  5.1469e-02,  6.3814e-01,\n",
       "          8.7007e-01, -6.7827e-02, -2.6016e-01, -1.0374e+00, -1.6607e+00,\n",
       "         -1.2337e+00, -1.0003e+00, -3.9118e-01, -1.2501e+00, -1.0936e+00,\n",
       "         -9.5480e-01, -6.2942e-01, -1.3498e+00, -4.3880e-01, -1.4588e-01,\n",
       "         -2.0934e+00, -6.2754e-01, -4.8123e-01, -4.8970e-01, -1.2342e+00,\n",
       "         -6.7019e-01,  9.7467e-02, -6.9497e-01, -1.2102e+00, -2.9577e-01,\n",
       "          6.0762e-01, -1.3790e-01, -3.0517e-01,  4.3112e-01,  7.1924e-01,\n",
       "         -7.5980e-02, -1.0310e+00, -1.2072e+00, -1.1289e+00, -1.0206e+00,\n",
       "         -1.7981e+00, -1.2883e+00, -1.4505e+00, -1.6278e+00, -1.4533e+00,\n",
       "         -1.7172e+00, -1.4888e+00, -5.1387e-02, -3.3337e-01, -6.5441e-01,\n",
       "          9.4376e-02, -1.2598e-01,  4.8515e-01,  4.0928e-01, -7.2313e-01,\n",
       "         -5.3534e-01, -1.3355e+00,  2.0752e-01,  8.8699e-01, -1.2828e+00,\n",
       "         -6.8099e-01,  6.8227e-01, -3.5551e-01, -1.2992e+00, -6.4262e-01,\n",
       "          6.6295e-01, -5.7380e-01, -1.3321e+00,  1.6075e-01, -9.2388e-01,\n",
       "         -5.7945e-01, -2.0434e+00, -1.1043e+00, -5.0261e-01, -5.2856e-01,\n",
       "          5.5766e-01,  1.3624e+00,  1.3506e-01,  4.9310e-01,  5.1870e-01,\n",
       "         -1.6233e-01,  6.8024e-01,  1.6846e-01,  4.1666e-01, -4.4633e-01,\n",
       "         -6.3090e-01, -8.7363e-01, -2.7558e-01, -8.0258e-01, -7.5153e-01,\n",
       "         -6.4642e-01, -1.9464e-01, -5.3978e-01,  1.8166e-01, -1.5033e-01,\n",
       "         -1.0386e+00, -1.0817e+00,  1.1017e-01,  7.0688e-02, -1.2966e-01,\n",
       "          5.3817e-01, -1.4719e-01, -2.1277e-01, -6.2717e-01, -6.0135e-01,\n",
       "         -6.4209e-01, -1.2373e+00, -9.8994e-01, -8.0082e-01, -1.6168e-01,\n",
       "          3.3416e-01,  1.5191e-01, -1.5190e+00, -1.7040e+00, -2.0898e-02,\n",
       "          6.1459e-01, -1.2864e+00, -7.5597e-01,  2.8343e-01, -4.3381e-01,\n",
       "         -1.1833e+00,  5.8266e-01,  1.6523e-01, -1.9095e+00, -1.7550e+00,\n",
       "         -5.2570e-01, -4.6506e-01, -3.4040e-01,  1.6622e-01,  8.6453e-01,\n",
       "          3.5859e-02,  3.0424e-01,  2.4085e+00,  7.0709e-01,  4.0282e-01,\n",
       "          8.8626e-01, -5.4417e-01,  4.6082e-01,  8.1535e-02,  7.4507e-01,\n",
       "          7.4752e-01,  1.6115e+00, -3.8648e-01,  1.4560e-01,  1.9862e-01,\n",
       "         -8.1519e-01, -2.0468e-01,  1.6659e+00,  1.7632e+00,  5.2425e-01,\n",
       "         -5.9735e-01,  4.5720e-01,  2.8206e-01,  5.4065e-01,  1.5446e-01,\n",
       "          1.3270e+00, -2.9431e-01, -2.7169e-01,  3.5573e-01,  1.8159e-01,\n",
       "          5.9237e-01,  1.9549e-01,  7.6623e-02, -5.7401e-01, -4.5537e-01,\n",
       "         -5.3357e-02,  1.4451e-01,  1.3807e+00,  9.0179e-01, -6.6990e-01,\n",
       "         -1.0129e-01,  2.4436e-01,  5.2193e-01, -2.3208e-01, -6.3081e-01,\n",
       "          6.3182e-01,  1.4626e+00,  1.0916e+00, -3.1639e-01,  6.1648e-01,\n",
       "         -5.2548e-01,  4.5913e-01,  1.2768e+00,  2.8549e+00,  8.9858e-01,\n",
       "         -1.4291e-01, -1.3785e+00, -2.5221e-01, -1.5680e-01,  1.7545e+00,\n",
       "          1.1654e+00,  6.3116e-01,  3.0895e-01,  9.4065e-01, -5.6912e-01,\n",
       "         -1.2050e-01,  4.3195e-01,  6.6978e-02,  6.1570e-01,  1.3173e-01,\n",
       "         -1.1317e-01,  2.4527e-02,  5.1156e-01, -9.0088e-01, -1.4836e+00,\n",
       "          4.1992e-02, -3.1919e-01,  9.9692e-01,  1.6995e+00,  1.2018e+00,\n",
       "         -3.6738e-02,  7.1611e-01,  7.7638e-01, -1.0971e+00,  1.3220e+00,\n",
       "         -9.8847e-01, -8.1862e-02, -5.3752e-01, -3.6508e-01,  1.1461e+00,\n",
       "         -1.4164e+00,  2.3263e-01,  1.2741e+00,  4.0880e-01,  1.0515e+00,\n",
       "          1.0524e+00,  9.7162e-01,  5.8257e-01,  4.9998e-01,  1.5767e-01,\n",
       "         -1.1216e+00, -9.0999e-01,  8.8603e-01,  3.3570e-01,  9.3211e-01,\n",
       "          1.8032e+00,  5.6126e-01,  1.4910e-01,  1.3024e+00,  6.4357e-01,\n",
       "         -7.5606e-01,  4.2792e-01,  8.2913e-01,  1.5283e+00,  1.4576e-01,\n",
       "         -7.5294e-01, -1.7642e-01, -6.6660e-01,  2.4842e-01,  1.6330e-01,\n",
       "          9.8623e-01,  2.5225e-02,  2.0649e-01, -1.2273e+00,  5.1452e-01,\n",
       "         -4.2186e-01, -5.6421e-01, -7.2606e-01,  2.0678e-01,  1.0681e+00,\n",
       "         -1.4505e+00,  1.8894e+00,  9.3884e-01,  6.1681e-01,  6.2667e-01,\n",
       "          6.7596e-01,  4.5627e-01, -2.1872e+00, -1.1096e+00, -3.4227e-01,\n",
       "         -5.3791e-01,  1.2790e-01,  7.9212e-01, -1.3902e-01, -1.7162e+00,\n",
       "         -6.4942e-01,  2.8133e-01,  5.3056e-01,  1.4042e+00,  1.1269e+00,\n",
       "          8.0320e-02, -1.7844e-01,  7.9730e-01, -9.0330e-02, -1.5013e+00,\n",
       "         -1.0486e+00, -1.1273e-01,  1.1736e+00,  2.3785e-01, -4.9246e-01,\n",
       "          9.6641e-01,  1.8580e-01,  7.3405e-01, -7.8496e-01,  4.5113e-01,\n",
       "          1.5171e-01, -1.5527e+00,  1.0611e+00,  2.4724e-01,  3.0905e-01,\n",
       "          3.2745e-01, -4.1555e-01,  6.1403e-01,  5.5775e-01,  9.8223e-01,\n",
       "          7.6543e-01, -5.4305e-01,  1.9159e+00,  1.4793e+00,  1.5913e+00,\n",
       "         -7.9975e-01,  4.0043e-01, -6.9734e-01,  8.7225e-01, -2.4238e-02,\n",
       "         -5.0561e-01,  1.0566e+00, -3.6572e-01, -5.2282e-01,  8.4781e-01,\n",
       "          2.1362e+00, -1.6047e-01, -5.5429e-02, -6.1966e-01,  4.0342e-01,\n",
       "          7.6010e-02,  1.2842e+00, -3.6349e-01,  2.4570e-01, -9.8759e-02,\n",
       "          6.8405e-01,  5.6958e-01, -8.0700e-01,  8.1335e-01,  2.2246e-01,\n",
       "          1.3121e-01,  1.4051e+00,  4.2837e-01,  1.9395e+00,  1.0118e+00,\n",
       "          7.6017e-01,  8.1537e-01,  2.1117e-01,  3.0176e-01,  2.3091e-02,\n",
       "         -1.1120e+00,  8.2216e-01, -5.3432e-01, -1.1703e+00, -2.1506e-02,\n",
       "         -3.5756e-01,  8.5265e-01,  7.6558e-01,  1.2010e+00, -2.6812e-01,\n",
       "          8.4341e-02,  1.2282e+00,  9.3460e-01,  3.9151e-01, -6.4634e-02,\n",
       "         -1.6594e+00,  1.3222e+00, -5.2976e-02,  1.2484e+00,  4.7735e-01,\n",
       "         -1.1304e+00,  6.0607e-01,  4.5637e-01, -6.3843e-01, -1.5779e+00,\n",
       "          9.9960e-01,  1.1659e-01,  6.9368e-01,  1.0277e+00,  3.2447e-01,\n",
       "          3.0785e-01,  2.3380e-01,  2.1215e-01, -4.2105e-01,  6.3301e-01,\n",
       "          7.1522e-02, -1.2745e+00, -6.4246e-02, -1.0375e+00,  7.4874e-01,\n",
       "          1.4666e-01,  1.4184e+00,  1.7098e-01, -9.2844e-01, -6.2366e-01,\n",
       "          3.6470e-01, -3.0764e-01, -1.7051e-01,  5.4250e-01,  1.5117e+00,\n",
       "         -8.6046e-01,  1.6645e+00,  1.1399e+00,  7.2655e-01,  1.7864e-01,\n",
       "          5.3626e-01,  3.3702e-01, -8.6937e-01,  4.7623e-01,  8.6222e-01,\n",
       "         -1.7283e+00, -1.4038e-01, -1.3966e+00, -4.9245e-01, -1.0381e+00,\n",
       "         -4.1984e-01,  7.6605e-01,  8.4975e-01,  4.9098e-01, -1.0161e+00,\n",
       "          8.9685e-01,  1.5960e+00,  1.1172e-01, -4.7839e-01,  5.0942e-01,\n",
       "          2.0530e+00, -2.8705e-02, -1.7610e-01,  6.2706e-01,  5.6788e-01,\n",
       "         -6.2747e-01, -4.0960e-01,  2.2401e-01,  1.0497e+00, -1.5284e-01,\n",
       "          1.1472e+00,  9.2515e-01, -1.3171e-01, -3.7262e-01,  1.2367e-01,\n",
       "         -5.6201e-01,  6.6285e-01, -7.1277e-01, -6.0576e-01,  1.1288e+00,\n",
       "          1.3152e-01,  9.6264e-02,  1.6494e+00,  1.8475e-01, -7.1070e-01,\n",
       "          1.3769e+00, -5.2400e-01,  1.0911e-01,  1.4278e+00, -7.7878e-01,\n",
       "          3.8968e-01,  2.1719e+00, -9.2238e-01,  1.8458e+00, -1.6205e+00,\n",
       "          2.7079e-01, -4.6000e-02,  6.6316e-01,  1.1222e+00,  4.2915e-01,\n",
       "          1.2415e+00, -4.6157e-01,  4.1604e-01, -5.3236e-02,  7.4174e-01,\n",
       "         -2.0347e-01, -4.3512e-03,  7.2568e-01,  7.5093e-01,  1.3992e+00,\n",
       "          3.9159e-01, -2.1942e-01, -7.5980e-02,  9.4586e-01,  9.3548e-01,\n",
       "         -3.8396e-01,  1.5607e+00,  1.0814e-01,  1.1899e+00, -4.8323e-01,\n",
       "          5.4406e-02,  6.9496e-01,  5.5969e-01,  6.2403e-01,  1.4090e+00,\n",
       "          9.0650e-01,  4.2626e-01,  3.9947e-01, -3.8512e-01,  1.0285e+00,\n",
       "          2.5967e-01,  3.1872e-01,  1.1866e+00,  6.2302e-01,  6.1699e-01,\n",
       "          3.1838e-01,  6.2810e-01,  2.4980e-01,  1.1812e+00, -5.3525e-01,\n",
       "         -9.4836e-01, -8.0444e-01,  1.0747e+00,  7.9249e-01,  1.4052e+00,\n",
       "          1.5599e-01,  6.1569e-01,  7.5488e-01,  1.1607e-01, -1.0008e-01,\n",
       "          9.8258e-01,  1.0604e+00,  1.5767e+00,  8.3320e-01,  4.8036e-01,\n",
       "         -9.5649e-02,  5.9844e-01,  7.6321e-01, -1.1937e+00,  3.8834e-01,\n",
       "         -9.7006e-01, -5.7169e-02, -1.1170e+00, -1.1570e+00,  1.4018e+00,\n",
       "          1.4570e+00, -9.6109e-02,  3.9150e-01,  1.3147e+00,  1.2357e-01,\n",
       "         -9.6567e-01,  1.2332e+00, -3.2352e-01,  1.4855e+00, -1.1481e+00,\n",
       "         -5.9002e-01,  4.6751e-01, -1.2441e+00,  1.5316e+00,  2.9501e-01,\n",
       "         -2.0716e+00, -1.3434e+00,  4.2983e-01,  6.7820e-01,  8.9080e-01,\n",
       "         -6.9785e-01,  7.3396e-02,  8.5529e-01,  1.5403e+00, -7.2142e-01,\n",
       "          1.3324e+00,  5.4161e-01, -7.9402e-01, -7.7979e-01, -2.4009e-01,\n",
       "          7.6444e-01,  1.7173e+00,  1.6560e+00,  1.0092e+00, -9.6706e-01,\n",
       "          1.3258e+00,  2.6445e-01,  1.6988e-01,  8.7092e-01,  8.7738e-01,\n",
       "          1.4525e+00,  8.4376e-01, -3.1147e-01,  6.0910e-01,  1.1614e+00,\n",
       "          1.4057e+00,  1.5368e+00,  1.9607e+00, -5.8933e-01, -6.2525e-01,\n",
       "          8.4807e-01, -6.0743e-01, -4.4427e-01, -6.0485e-02,  1.1772e+00,\n",
       "          2.3434e-02,  1.4602e+00,  1.0447e+00, -3.5260e-01, -3.3342e-01,\n",
       "          7.9738e-01,  6.7161e-02, -4.9177e-01,  1.4130e+00, -4.4205e-01,\n",
       "          1.1081e+00, -1.4660e+00,  9.1764e-01, -1.2315e+00, -2.1279e+00,\n",
       "          3.4352e-01,  1.8801e+00, -2.9501e-01, -5.2033e-01,  1.6989e+00,\n",
       "          1.0654e+00, -2.3028e-01,  1.1632e+00,  1.3299e+00, -1.7805e-02,\n",
       "          1.7804e-01, -2.3605e-01, -5.6561e-01, -1.2376e+00,  2.6372e-01,\n",
       "         -5.3959e-01,  4.2638e-01,  7.1150e-01, -1.2517e-01, -9.9046e-01,\n",
       "         -5.7631e-01,  1.6924e+00,  5.7562e-01,  1.8998e+00,  1.9767e+00,\n",
       "         -9.3444e-01, -5.1298e-01,  2.0510e+00,  5.4936e-01,  1.1214e+00,\n",
       "          7.1010e-02, -7.9426e-01,  1.2424e+00, -1.1466e+00,  1.1664e+00,\n",
       "          1.3129e+00,  9.1997e-01,  9.5828e-01, -3.0611e-01, -1.8514e+00,\n",
       "         -1.2614e-01,  1.9377e-01, -1.3621e-01,  1.1727e-01, -1.8741e-01,\n",
       "         -5.0991e-01,  6.2850e-01, -9.5378e-01,  4.6307e-01, -4.5621e-01,\n",
       "         -6.8832e-01, -8.6173e-01, -3.8477e-01, -6.9126e-02,  1.3434e+00,\n",
       "         -3.7429e-01,  8.9061e-02,  1.3131e-01, -1.5903e+00, -2.9994e-02,\n",
       "         -7.4033e-01,  4.0341e-01,  2.6305e-01, -1.2587e-01, -2.1516e-01,\n",
       "         -2.5476e-01, -6.2705e-01, -1.7640e-01,  1.3813e-01, -6.8099e-01,\n",
       "         -5.6108e-01, -1.3308e+00,  2.2899e-01,  6.9473e-01, -5.2555e-01,\n",
       "          1.3972e-01, -4.3241e-01, -7.2046e-01,  2.0479e-02,  4.8555e-01,\n",
       "         -5.9802e-01, -3.3839e-01, -6.8512e-01,  1.3454e-01, -9.6634e-01,\n",
       "          5.2246e-01,  4.7986e-01, -3.7969e-01, -8.5674e-01, -1.2079e+00,\n",
       "         -1.4022e-01,  3.5311e-01, -6.5602e-01,  1.0514e+00,  1.0201e-01,\n",
       "         -4.2593e-02,  9.5590e-01, -2.0966e-01, -5.3228e-01, -1.8748e+00,\n",
       "          1.1798e+00, -1.4250e+00,  5.9782e-01,  2.7636e-01, -5.3443e-01,\n",
       "         -6.6916e-01,  2.4684e-01,  5.2877e-01, -5.6477e-01, -1.0373e+00,\n",
       "         -1.3785e+00, -2.4571e+00,  1.2460e+00, -1.5984e-01, -7.4987e-01,\n",
       "         -3.7264e-01, -1.4363e+00, -9.7402e-01, -2.1860e+00, -9.5842e-01,\n",
       "         -5.0808e-01,  4.1171e-02, -4.7079e-01,  1.2134e+00,  1.2171e+00]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward propagation to the data\n",
    "prediction = model(data)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the loss and backpropagating it\n",
    "loss = (prediction - labels).sum()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading an optimizer (stochastic gradient descent)\n",
    "optim = torch.optim.SGD(model.parameters(), lr = 1e-2, \n",
    "        momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step adjust the parameters by the gradient descent\n",
    "optim.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differentiation in Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requires_grad sign that every operation on the tensor \n",
    "# should be tracked\n",
    "a = torch.tensor([2., 3.], requires_grad=True)\n",
    "b = torch.tensor([6., 4.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${Q = 3a^3 - b²}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-12.,  65.], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q is a tensor created using a and b -> Q is the error of a NN\n",
    "Q = 3*a**3-b**2\n",
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${{\\frac{\\partial Q}{\\partial a}} = 9a²}$ ______________ ${{\\frac{\\partial Q}{\\partial b}} = -2b}$ ______________ ${\\frac{dQ}{dQ} = 1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on the gradient parameter we must pass the gradient of Q (1)\n",
    "# repeating the shape of Q\n",
    "external_grad = torch.tensor([1., 1.])\n",
    "Q.backward(gradient=external_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A gradients - Calculated tensor([36., 81.], grad_fn=<MulBackward0>) | Observed tensor([0., 0.])\n",
      "B gradients - Calculated tensor([-12.,  -8.], grad_fn=<MulBackward0>) | Observed tensor([-0., -0.])\n"
     ]
    }
   ],
   "source": [
    "# printing the gradients\n",
    "print(f\"A gradients - Calculated {9*a**2} | Observed {a.grad}\")\n",
    "print(f\"B gradients - Calculated {-2*b} | Observed {b.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Freezing the autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suposing we have the model structure but we want to modify the classifier\n",
    "# the classifier is on the fc 'layer'\n",
    "\n",
    "# its gradients are not frozen\n",
    "model.fc = nn.Linear(512, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizing the classifier\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cde81edf15c274bb0721111e8fc32fb5a80fe701fa2da5fabb1e915411a95d5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
